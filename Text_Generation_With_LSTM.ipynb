{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mals77703/text-gen-lstm/blob/core/Text_Generation_With_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Small LSTM Network to Generate Text for Alice in Wonderland"
      ],
      "metadata": {
        "id": "62d2lNdAai09"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhxQoVbbMe93"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical  # Use to_categorical instead of np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "metadata": {
        "id": "-QXEwe2eM9Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "2EqvSGP8NDHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK-rcFQwO1o_",
        "outputId": "aea73383-8a53-41d5-c6cd-90bcdf3497ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  163918\n",
            "Total Vocab:  65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCN4q4LrPAe6",
        "outputId": "8e69803c-f676-4d52-88fd-d78f0f26e357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  163818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "from keras.utils import to_categorical # Import the necessary module\n",
        "y = to_categorical(dataY)"
      ],
      "metadata": {
        "id": "Yj6Vg8-hPPC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EjKZ365Pa2L",
        "outputId": "fc1760d5-55a8-4c59-8ed2-b6481e2e5338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.keras\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "GtYT0EuxPbPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppFt_WUuPbTD",
        "outputId": "4f0b5487-fc72-4a64-f7d6-0057f7009a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1279/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0709\n",
            "Epoch 1: loss improved from inf to 2.08449, saving model to weights-improvement-01-2.0845.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 2.0709\n",
            "Epoch 2/20\n",
            "\u001b[1m1278/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0555\n",
            "Epoch 2: loss improved from 2.08449 to 2.06189, saving model to weights-improvement-02-2.0619.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 2.0555\n",
            "Epoch 3/20\n",
            "\u001b[1m1279/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0313\n",
            "Epoch 3: loss improved from 2.06189 to 2.04263, saving model to weights-improvement-03-2.0426.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 2.0313\n",
            "Epoch 4/20\n",
            "\u001b[1m1279/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0174\n",
            "Epoch 4: loss improved from 2.04263 to 2.02474, saving model to weights-improvement-04-2.0247.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 2.0174\n",
            "Epoch 5/20\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9966\n",
            "Epoch 5: loss improved from 2.02474 to 2.00489, saving model to weights-improvement-05-2.0049.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.9966\n",
            "Epoch 6/20\n",
            "\u001b[1m1277/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9779\n",
            "Epoch 6: loss improved from 2.00489 to 1.98789, saving model to weights-improvement-06-1.9879.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 1.9779\n",
            "Epoch 7/20\n",
            "\u001b[1m1279/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9620\n",
            "Epoch 7: loss improved from 1.98789 to 1.97306, saving model to weights-improvement-07-1.9731.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 1.9620\n",
            "Epoch 8/20\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9477\n",
            "Epoch 8: loss improved from 1.97306 to 1.96279, saving model to weights-improvement-08-1.9628.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.9477\n",
            "Epoch 9/20\n",
            "\u001b[1m1277/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9325\n",
            "Epoch 9: loss improved from 1.96279 to 1.93969, saving model to weights-improvement-09-1.9397.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.9326\n",
            "Epoch 10/20\n",
            "\u001b[1m1279/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9113\n",
            "Epoch 10: loss improved from 1.93969 to 1.92767, saving model to weights-improvement-10-1.9277.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 1.9113\n",
            "Epoch 11/20\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8990\n",
            "Epoch 11: loss improved from 1.92767 to 1.91566, saving model to weights-improvement-11-1.9157.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.8990\n",
            "Epoch 12/20\n",
            "\u001b[1m1278/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8937\n",
            "Epoch 12: loss improved from 1.91566 to 1.90229, saving model to weights-improvement-12-1.9023.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 1.8937\n",
            "Epoch 13/20\n",
            "\u001b[1m1278/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8792\n",
            "Epoch 13: loss improved from 1.90229 to 1.89088, saving model to weights-improvement-13-1.8909.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 1.8792\n",
            "Epoch 14/20\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8722\n",
            "Epoch 14: loss improved from 1.89088 to 1.88944, saving model to weights-improvement-14-1.8894.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 1.8722\n",
            "Epoch 15/20\n",
            "\u001b[1m1278/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8560\n",
            "Epoch 15: loss improved from 1.88944 to 1.87266, saving model to weights-improvement-15-1.8727.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.8560\n",
            "Epoch 16/20\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8510\n",
            "Epoch 16: loss improved from 1.87266 to 1.86758, saving model to weights-improvement-16-1.8676.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.8510\n",
            "Epoch 17/20\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8320\n",
            "Epoch 17: loss improved from 1.86758 to 1.84932, saving model to weights-improvement-17-1.8493.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.8320\n",
            "Epoch 18/20\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8299\n",
            "Epoch 18: loss improved from 1.84932 to 1.84129, saving model to weights-improvement-18-1.8413.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.8300\n",
            "Epoch 19/20\n",
            "\u001b[1m1278/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8157\n",
            "Epoch 19: loss improved from 1.84129 to 1.82679, saving model to weights-improvement-19-1.8268.keras\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.8157\n",
            "Epoch 20/20\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8157\n",
            "Epoch 20: loss did not improve from 1.82679\n",
            "\u001b[1m1280/1280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 1.8157\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e9cdc592230>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SXwtpSmlasUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls weights-improvement-19-2.1330.keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3COktEWUD3c",
        "outputId": "bd690c2e-a5d5-4485-cfc7-877eda2e5d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights-improvement-19-2.1330.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##########################################################################################"
      ],
      "metadata": {
        "id": "dB0Lvs15eym_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load LSTM network and generate text"
      ],
      "metadata": {
        "id": "dkeHc86ia8pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "TVeQ56coa11q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n"
      ],
      "metadata": {
        "id": "prQm9NG1bDn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n"
      ],
      "metadata": {
        "id": "RJ-7IqScbHa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn_XPY-sbOza",
        "outputId": "56841304-7045-43fd-c6bb-3f270a0b94a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  163918\n",
            "Total Vocab:  65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qp5Mh-Bbf-l",
        "outputId": "7a8fc59a-3f90-4ec0-ad32-aeb07bc6a119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  163818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "import numpy\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qiz0BrSfD-P",
        "outputId": "e06d9487-ac8b-4a21-c6de-9b9eadf423ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = to_categorical(dataY)"
      ],
      "metadata": {
        "id": "yJ8Qx0gYeTwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy1-rdXTeaYv",
        "outputId": "3a5c4075-a989-4a5e-a426-96a988a988b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the network weights\n",
        "filename = \"weights-improvement-19-1.8268.keras\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "ArsSNCECbvjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NTO7eZveII-",
        "outputId": "fe46ce15-a81d-48ec-d858-6a2f7bc0e28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" g her ‘_turtle soup_,’ will you, old\n",
            "fellow?”\n",
            "\n",
            "the mock turtle sighed deeply, and began, in a voice  \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate characters\n",
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvs_Y_qEeIh8",
        "outputId": "56943141-726f-432a-8685-aa30dc9bd565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toene al anl of the could so the tooes she had goe the thieg oh the tablis. and the whrt sard then it was toe pibel to the thoe  the had not toe toieg of the tooe, and the woide saade of soene of the could  ohe was aol the wordd her eros she was tole the tas th the thoe whet she was not in the tirl wh hen the hirt, she was not io was ho tie winl, and then sored to tee thet she was not of tiate, and whsy hose of the couro, and the woidd sard tole to het hn the tinl, and the woidd sard oetelrly an the could so the tooe, and the white rabbit wes on to sie thilg sat she tise the was not in the tirl wfth saldin whth the thing was soee and the wools the had no the toilg oh the tooe, and the white rabbit wes on toee a fots of the cank of the tail wf hoawt tat an the could, \n",
            "“hh you din’t bel tou soee to the toen an _nl,” said the monk tuitlir. “io you dnol wat io the soiee oo the then wou,”\n",
            "\n",
            "“hom toe mork of the mors of the soite oo the soon,” said the monk tuiteid an a louuten to the sreee. \n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##########################################################"
      ],
      "metadata": {
        "id": "ImyHPEgsbd_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Larger LSTM Network to Generate Text for Alice in Wonderland"
      ],
      "metadata": {
        "id": "42-rmVukf6ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Qt3IZJI1fnXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "metadata": {
        "id": "dysLUkg5gCOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "3KKC5tIKg71O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GROazqLlgM3T",
        "outputId": "ca2db0b1-29b3-47e9-f665-0792f386b35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  163918\n",
            "Total Vocab:  65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNhFnBBMgX29",
        "outputId": "ab489ad3-9262-4c60-8be7-c8c2d9e80b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  163818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "import numpy\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4rjA1buhczn",
        "outputId": "e49fca70-f56e-428d-e705-3eb403992b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = to_categorical(dataY)"
      ],
      "metadata": {
        "id": "YuPztdergdJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWol7GXMghN0",
        "outputId": "b6de7204-2e93-41a1-937b-204cab81bc4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.keras\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG9W1Z14gmQv",
        "outputId": "f0a97201-2a7b-4237-85bf-3acb920a5267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 20ms/step - loss: 3.0051\n",
            "Epoch 2/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 2.5991\n",
            "Epoch 3/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 20ms/step - loss: 2.3990\n",
            "Epoch 4/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 21ms/step - loss: 2.2443\n",
            "Epoch 5/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 2.1467\n",
            "Epoch 6/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 2.0437\n",
            "Epoch 7/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 20ms/step - loss: 1.9693\n",
            "Epoch 8/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.9146\n",
            "Epoch 9/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 20ms/step - loss: 1.8545\n",
            "Epoch 10/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.8071\n",
            "Epoch 11/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.7658\n",
            "Epoch 12/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.7311\n",
            "Epoch 13/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.6951\n",
            "Epoch 14/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.6653\n",
            "Epoch 15/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 20ms/step - loss: 1.6369\n",
            "Epoch 16/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 20ms/step - loss: 1.6074\n",
            "Epoch 17/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.5956\n",
            "Epoch 18/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.5725\n",
            "Epoch 19/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.5409\n",
            "Epoch 20/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 20ms/step - loss: 1.5323\n",
            "Epoch 21/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 20ms/step - loss: 1.5107\n",
            "Epoch 22/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.5000\n",
            "Epoch 23/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.4759\n",
            "Epoch 24/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 20ms/step - loss: 1.4561\n",
            "Epoch 25/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.4512\n",
            "Epoch 26/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.4241\n",
            "Epoch 27/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.4472\n",
            "Epoch 28/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.7886\n",
            "Epoch 29/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.7353\n",
            "Epoch 30/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.4377\n",
            "Epoch 31/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 20ms/step - loss: 1.7079\n",
            "Epoch 32/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 20ms/step - loss: 1.6941\n",
            "Epoch 33/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.6844\n",
            "Epoch 34/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 20ms/step - loss: 1.6326\n",
            "Epoch 35/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 20ms/step - loss: 1.6214\n",
            "Epoch 36/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 20ms/step - loss: 1.4405\n",
            "Epoch 37/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 20ms/step - loss: 1.6166\n",
            "Epoch 38/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.6342\n",
            "Epoch 39/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.6313\n",
            "Epoch 40/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.6212\n",
            "Epoch 41/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.6139\n",
            "Epoch 42/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.6185\n",
            "Epoch 43/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.6127\n",
            "Epoch 44/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.5759\n",
            "Epoch 45/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.4984\n",
            "Epoch 46/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 1.8900\n",
            "Epoch 47/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 2.4068\n",
            "Epoch 48/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 2.2946\n",
            "Epoch 49/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 2.1882\n",
            "Epoch 50/50\n",
            "\u001b[1m2560/2560\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 20ms/step - loss: 2.0953\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e9c84209030>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####################################################################"
      ],
      "metadata": {
        "id": "ONissqk_gwS_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Larger LSTM network and generate text"
      ],
      "metadata": {
        "id": "solOIoCnh3kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "E7AQOxOCh2m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n"
      ],
      "metadata": {
        "id": "3iXUYPMUjkew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "i_UTvM8XjuTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBdy5tcij0Gn",
        "outputId": "60ff6aa0-2859-40b0-a292-d13b8b8113d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  163918\n",
            "Total Vocab:  65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goCWnpWzisJn",
        "outputId": "cd23ca57-89c6-430a-e74c-ed3de582a4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  163818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = to_categorical(dataY)\n"
      ],
      "metadata": {
        "id": "nBNZLCmnixvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6PwtF6vi1Aw",
        "outputId": "18f18f4e-0122-4065-d988-ab9e99c5f0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the network weights\n",
        "filename = \"weights-improvement-36-1.4484-bigger.keras\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "tl3iQmcMi7-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W220d68SjBhL",
        "outputId": "2bbca28a-54e0-4dfe-9921-afde625b9015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" r a dunce? go on!”\n",
            "\n",
            "“i’m a poor man,” the hatter went on, “and most things twinkled after\n",
            "that—only  \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate characters\n",
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_NE5R7xjGDI",
        "outputId": "80b4179f-70d9-40ed-a343-d347813f88b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the same thing is to say ”\n",
            "\n",
            "“i mever sat the dookouse ” said the king. \n",
            "“then it mu heard of tomeshing ” said the king.\n",
            "\n",
            "“then it must be a very lrchte your mary beli,” she said to he said to the gryphon. “i wonder wha was to of the same thing is to say ”\n",
            "\n",
            "“i mhse you say the sea ” said the king. \n",
            "“the qabbit siate would be a very gind that!” said the kock turtle.\n",
            "\n",
            "“then i should like to tay the season in the sea,” she maie the was salking to herself, “i wonder that yoee it mowe to be a marge patty\n",
            "that makes the ming! and the morely to be the sime the door and she was so begin that she was not a mittle biil was as the sabbit say the wiite rabbit hnt the was suine to better to say “the had no the same shing is to be a large pasty\n",
            "was the same shing so the boorersat with the soop of the court, and she went on to sas off and the kittle goore of the court, and she went on to say “the ma bone the rame thing is to be a lirtle bisd of the too of the way toe wiich of the court. and she said t\n",
            "Done.\n"
          ]
        }
      ]
    }
  ]
}